# Environment variables for jurDroids configuration
# Copy this file to .env and fill in your actual values.
# IMPORTANT: Add .env to your .gitignore file to prevent committing secrets!

# --- OpenAI Configuration ---
# Uncomment and set if using OpenAI API
# OPENAI_API_KEY="your_openai_api_key_here"
# OPENAI_MODEL_NAME="gpt-4-turbo-preview" # Or another model like gpt-4o, gpt-3.5-turbo

# --- xAI Configuration ---
# XAI_API_KEY=your-xai-api-key
# LLM_BACKEND=xai
# LOG_LEVEL=INFO

# --- Azure OpenAI Configuration ---
# Uncomment and set if using Azure OpenAI services
# AZURE_OPENAI_ENDPOINT="https://your-instance-name.openai.azure.com/"
# AZURE_OPENAI_API_KEY="your_azure_openai_api_key_here"
# AZURE_DEPLOYMENT_NAME="your_model_deployment_name" # The deployment name you created in Azure AI Studio
# AZURE_API_VERSION="2024-02-01" # Example API version, check Azure documentation for current versions

# --- Google Cloud Vertex AI Configuration ---
# Uncomment and set if using Google Cloud Vertex AI
# GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/service-account-keyfile.json" # Path to your service account key file
# GCP_PROJECT_ID="your-gcp-project-id"
# GCP_LOCATION="us-central1" # Or your GCP region
# VERTEX_MODEL_NAME="gemini-1.5-flash-001" # Or another Gemini model ID like gemini-1.0-pro

# --- Hugging Face Configuration ---
# Uncomment and set if using Hugging Face models (Inference API or local Transformers)
# HF_API_TOKEN="hf_your_huggingface_api_token" # Needed for gated models or Inference API usage
# HF_MODEL_NAME="mistralai/Mistral-7B-Instruct-v0.2" # Example model ID from Hugging Face Hub

# --- Local LLM Configuration (e.g., Ollama, LM Studio) ---
# Uncomment and set if connecting to a locally running LLM server with an OpenAI-compatible API
# LOCAL_LLM_API_BASE="http://localhost:11434/v1" # Example for Ollama default endpoint
# LOCAL_LLM_MODEL_NAME="llama3:instruct" # The name of the model you are serving locally
# LOCAL_LLM_API_KEY="ollama" # Often a placeholder like 'ollama' or 'none' is sufficient, check your local server docs

# --- Other Optional Configuration ---
# You can add other environment-specific settings here if needed
# EXAMPLE_SETTING="example_value"